{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MwangiMuriuki2003/MURIUKI/blob/main/Copy_of_fcc_sms_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow tensorflow-datasets\n",
        "!pip install tensorflow\n",
        "!pip install -q tensorflow-datasets\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d23ed4a0"
      },
      "source": [
        "train_data = pd.read_csv(train_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "test_data = pd.read_csv(test_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "display(train_data.head())\n",
        "display(test_data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "# get data files directly in this cell to ensure they exist\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv -O train-data.tsv.51\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv -O valid-data.tsv.51\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import pandas as pd # Ensure pandas is imported if not already in this cell\n",
        "\n",
        "train_file_path = \"train-data.tsv.51\"\n",
        "test_file_path = \"valid-data.tsv.51\"\n",
        "\n",
        "# Load the data directly in this cell to ensure it's available\n",
        "train_data = pd.read_csv(train_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "test_data = pd.read_csv(test_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# Split into features (X) and labels (y)\n",
        "X_train = train_data['message']\n",
        "y_train = train_data['label']\n",
        "\n",
        "# Preprocess and vectorize the text data\n",
        "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Function to predict the message\n",
        "def predict_message(message):\n",
        "    # Preprocess the message\n",
        "    message_vec = vectorizer.transform([message])\n",
        "    # Predict probability\n",
        "    prob = model.predict_proba(message_vec)[0]\n",
        "    # Predict label\n",
        "    label = model.predict(message_vec)[0]\n",
        "    # Return [probability_of_spam, label]\n",
        "    return [prob[1], label]\n",
        "\n",
        "# Model and prediction function defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "# The predict_message function is already defined in cell g_h508FEClxO, so we will use that.\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n",
        "\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "X_test = test_data['message']\n",
        "y_test = test_data['label']\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"\\nModel Evaluation on Test Data:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4217ecd9"
      },
      "source": [
        "# Task\n",
        "Improve the accuracy of the spam classification model by analyzing misclassified predictions, enhancing the TF-IDF vectorizer with N-grams for text processing, and then retraining and re-evaluating the model's performance on the \"train-data.tsv.51\" and \"valid-data.tsv.51\" datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b776d86"
      },
      "source": [
        "## Identify Misclassified Predictions\n",
        "\n",
        "### Subtask:\n",
        "Create a DataFrame to display test messages, their true labels, and the model's predictions. Highlight the messages that were misclassified to understand the types of errors the model is making. This will help in identifying patterns in the misclassified 'spam' or 'ham' messages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5ce4816"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify misclassified predictions, I will create a DataFrame that combines the test messages, their actual labels, and the model's predictions. Then, I will add a column to indicate whether each prediction was misclassified, and filter this DataFrame to show only the misclassified entries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cf3ac42"
      },
      "source": [
        "predictions_df = pd.DataFrame({\n",
        "    'message': X_test,\n",
        "    'actual_label': y_test,\n",
        "    'predicted_label': y_pred\n",
        "})\n",
        "\n",
        "predictions_df['is_misclassified'] = (predictions_df['actual_label'] != predictions_df['predicted_label'])\n",
        "\n",
        "misclassified_df = predictions_df[predictions_df['is_misclassified']]\n",
        "\n",
        "print(\"Misclassified Predictions:\")\n",
        "display(misclassified_df.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "218917b3"
      },
      "source": [
        "## Analyze False Negatives and False Positives\n",
        "\n",
        "### Subtask:\n",
        "Examine the misclassified messages from the previous step. Specifically, look at 'spam' messages classified as 'ham' (false negatives) and 'ham' messages classified as 'spam' (false positives). This will help in understanding what features the model is missing or misinterpreting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9f6a67c"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify false negatives, I will filter the 'misclassified_df' where the actual label is 'spam' and the predicted label is 'ham'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "179372a3"
      },
      "source": [
        "false_negatives_df = misclassified_df[(misclassified_df['actual_label'] == 'spam') & (misclassified_df['predicted_label'] == 'ham')]\n",
        "print(\"False Negatives (Actual Spam, Predicted Ham):\")\n",
        "display(false_negatives_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9538415b"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify false positives, I will filter the 'misclassified_df' where the actual label is 'ham' and the predicted label is 'spam'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290a6bc9"
      },
      "source": [
        "false_positives_df = misclassified_df[(misclassified_df['actual_label'] == 'ham') & (misclassified_df['predicted_label'] == 'spam')]\n",
        "print(\"False Positives (Actual Ham, Predicted Spam):\")\n",
        "display(false_positives_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4949a6b1"
      },
      "source": [
        "## Enhance TF-IDF with N-grams\n",
        "\n",
        "### Subtask:\n",
        "Modify the `TfidfVectorizer` to include N-grams (e.g., unigrams and bigrams) to capture more context from the text. This can improve the model's ability to differentiate between similar-sounding but semantically different messages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd66e0bd"
      },
      "source": [
        "**Reasoning**:\n",
        "To enhance the TF-IDF vectorizer with N-grams, I will re-initialize the `TfidfVectorizer` with `ngram_range=(1, 2)` to include unigrams and bigrams, then apply it to both the training and test datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6104be0a"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True, ngram_range=(1, 2))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "print(\"TF-IDF Vectorizer re-initialized with N-grams and applied to training and test data.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "487a4054"
      },
      "source": [
        "## Retrain and Re-evaluate Model\n",
        "\n",
        "### Subtask:\n",
        "After updating the `TfidfVectorizer`, retrain the `MultinomialNB` model with the new vectorized data. Then, re-run the test predictions and model evaluation to check for improvement in accuracy, precision, recall, and F1-score, especially for the 'spam' class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d5849c7"
      },
      "source": [
        "**Reasoning**:\n",
        "To retrain the model with the updated N-gram vectorized data, I will instantiate a new MultinomialNB model, train it with the N-gram vectorized training data, make predictions on the N-gram vectorized test data, and then print the accuracy score and classification report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25ee429e"
      },
      "source": [
        "model_ngram = MultinomialNB()\n",
        "model_ngram.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred_new = model_ngram.predict(X_test_vec)\n",
        "\n",
        "print(\"\\nModel Evaluation with N-grams on Test Data:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_new):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "225db351"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the improvements made to the model's performance and discuss any further steps that could be taken if necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51070266"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The model's performance has significantly improved, particularly in its precision for classifying 'spam'. Initially, the model produced 39 false negatives (actual spam classified as ham) and 0 false positives (actual ham classified as spam). After enhancing the TF-IDF vectorizer with N-grams and retraining, the model achieved perfect precision (1.00) for the 'spam' class, meaning that when it predicts a message is spam, it is always correct. Its recall for 'spam' is 0.70, indicating it identifies 70% of actual spam messages.\n",
        "\n",
        "Further steps could include:\n",
        "*   Investigating the remaining 30% of actual spam messages that are still being missed by the model (false negatives) to identify common characteristics or vocabulary that could be better captured.\n",
        "*   Experimenting with different N-gram ranges or more advanced text preprocessing techniques.\n",
        "*   Exploring other classification algorithms or ensemble methods to potentially improve recall for the 'spam' class without sacrificing the high precision.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The initial model misclassified 39 'spam' messages as 'ham' (false negatives) and had no 'ham' messages misclassified as 'spam' (false positives).\n",
        "*   Enhancing the TF-IDF vectorizer with N-grams (unigrams and bigrams) for text processing was successfully implemented.\n",
        "*   After retraining with N-grams, the model achieved an overall accuracy of 0.9598 on the test data.\n",
        "*   The retrained model demonstrated excellent performance for the 'ham' class, with a precision of 0.96, recall of 1.00, and F1-score of 0.98.\n",
        "*   For the 'spam' class, the model achieved a perfect precision of 1.00, meaning no legitimate 'ham' messages were incorrectly classified as 'spam'. However, the recall for 'spam' was 0.70, indicating that 30% of actual spam messages were still missed.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The current model excels at avoiding false positives (classifying legitimate messages as spam), which is crucial for user experience. However, there's room to improve its ability to detect all spam (increase recall for 'spam').\n",
        "*   Future efforts should focus on analyzing the characteristics of the remaining 30% of undetected spam messages (false negatives) to further refine text features or explore alternative modeling approaches that can boost spam recall without negatively impacting the achieved high precision.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}